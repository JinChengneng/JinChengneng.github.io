<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[【面试经验】微信搜索推荐团队机器学习数据挖掘实习生]]></title>
    <url>%2F2018%2F03%2F13%2F%E3%80%90%E9%9D%A2%E8%AF%95%E7%BB%8F%E9%AA%8C%E3%80%91%E5%BE%AE%E4%BF%A1%E6%90%9C%E7%B4%A2%E6%8E%A8%E8%8D%90%E5%9B%A2%E9%98%9F%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98%E5%AE%9E%E4%B9%A0%E7%94%9F%2F</url>
    <content type="text"><![CDATA[简单记录了面试过程中的问题，以供自己复习归纳和同方向的同学参考借鉴。 职业规划 你能在公司工作工作到几月？每星期能到岗多久？ 你打算读研吗？ 算法 在一个经过排序的数组中插入一个数，返回该数的下标。（二分查找） 1234find the index of the insert position: [1,3,5,9] 3 return 1[1,3,5,9] 0 return 0 [1,3,5,9] 40 return 4 找到一个数组中的最大和子数组。（动态规划）12find the subarray in a list has the largest su[-2, 1,-3,4,-1,2,1,-5,4] [4,-1,2,1] has the biggest return 6 机器学习和项目经验 有哪些聚类方法？讲一下工作原理。 什么是过拟合？有哪些防止过拟合的方法？ 有哪些正则化的方法？ 有哪些降维的方法？你用过哪些？（深度学习和机器学习领域） 你了解L（1）L（2）吗？原理是什么？ 机器学习有哪些常用的包？用过sklearn吗？ 讲一个你喜欢的人工智能的现实应用。 你打的这几道赛题数据量是多少？有数据量大的项目经验吗？ 项目里用过深度学习吗？RNN和LSTM有什么区别？LSTM的原理是什么？ linear regression和logistic regression的区别在哪里？]]></content>
  </entry>
  <entry>
    <title><![CDATA[【TAIL CAMP】NLP Task：手写作文自动评分]]></title>
    <url>%2F2018%2F02%2F10%2FTAIL%20CAMP%20NLP%20Task2%2F</url>
    <content type="text"><![CDATA[主要目标 学习使用textblob 学习readability的计算方法和相关工具 自动作文评分理论与方法学习 Day 1: 安装并学习使用 textblob 工具，学习parsing相关知识 今天我们将学习使用另一个nlp常用工具textblob，通过使用这个工具，学习其中的Part-of-speech Tagging，Spelling Correction，n-gram等概念 阅读nltk book 第八章节，学习parsing概念 安装textblob 学习textblob功能点 Day2: 学习Readability的定义和计算方法，学习使用工具textstat 和 readability。今天我们学习nlp中文章可读性的定义和计算方法，同时会用工具去计算。文章的可读性在自动作文评分，分级阅读等领域都有应用。 学习readability的定义 学习使用工具 textstat 学习使用工具 readability Day3: 学习Keras的安装和使用今天我们学习Keras,掌握一种快速搭建和使用深度神经网络的工具，可选择用于后面建立基于深度学习的自动作文评分 Keras 的介绍和安装 中文版本英文版本 学习使用keras 中文教程 使用keras对文本进行处理和编码 中文教程 Day4&amp;5: 阅读论文，学习自动作文评分的理论和方法前面几天我们已经学习了可以用来进行自动作文评分的一些概念和方法，接下来，我们通过阅读几片论文，了解和学习目前自动作文评分的主流的理论和方法。人工进行特征选择的方案，能够给写作文的用户带来更多的反馈信息，一定程度可以指导用户在弱项上进行提升；相比之下，基于深度学习的方法可能可以得到好的性能，但是是一个黑盒，从中没有办法获得更多的反馈；大家根据个人情况，可以充分发挥，例如做一些混合的系统等。以下内容作为同学们实现系统的参考： 参考阅读材料： 人工进行特征选择的评分系统 基于深度学习方法的评分系统 目前市面上比较权威的一个系统：ETS的e-rater评分系统 Day6: 设计方案，进行机器自动评分下面的链接是使用基于深度学习的方法进行作文自动评分的样例（前面提供论文的一个实现），可以作为一个实现方案的参考，同时大家可以自行设计自己的网络拓扑去做一些实验尝试。 此外，需要注意的是，我们选择的数据比样例少，所以考虑使用cpu模式去做实验，而样例使用了gpu模式。 参考链接]]></content>
  </entry>
  <entry>
    <title><![CDATA[【TAIL CAMP】NLP Task：句子语义相似度预测]]></title>
    <url>%2F2018%2F02%2F01%2FTAIL%20CAMP%20NLP%20Task1%2F</url>
    <content type="text"><![CDATA[主要目标 学习nltk，gensim等基本自然语言处理工具 学习机器学习基本工具Sklearn 相似度计算理论与方法学习 Day1 nltk，python学习使用nltk,python，同时掌握nlp的一些基本处理技巧和方法，例如tokenize，stem等 今天主要把推荐书籍的第五章节前面的内容，选择性看一遍（根据自身的情况选择），同时把里面涉及的python代码敲一敲(做文中的example)。主要学习python的数据类型和使用，以及nlp的一些基本概念。 安装nltk 安装教程 学习《Natural Language Processing with Python》一书前6章节，进行文本tokenize，stem等操作 Day 2: gensim 今天我们主要学习使用nlp中比较流行的一种词向量生成方法word2vec，gensim是其在python环境下的实现。除此之外，gensim本身还带有其他的一些例如特征提取，主题模型计算等功能 安装gensim 安装教程 Gensim主要功能介绍，学习tf-idf提取等功能 Gensim工具例子: 学习使用gensim来提取，词向量等特征 Day3: scikit-learnscikit-learn安装和例子学习，学习使用工具进行拟合。 scikit-learn是机器学习领域广泛被使用的一个python工具，里面集成了大量的机器学习算法。今天我们学习其中的Ridge Regression 和 svr方法，Ridge Regression使用比较简单，svr是深度学习前的主流方法(里面现在也集成了深度学习的工具，有兴趣的同学可以尝试)。后面可以选择使用这些方法对相似度数据进行拟合。 官网主页 安装 scikit-learn 教程 学习使用 scikit-learn 进行拟合 Ridge Regression教程 Svr教程 说明： 若由于某些原因链接打不开，可以从主页点进去试试 Ridge Regression：主页 -&gt; Regression -&gt; 1.1.2 Ridge Regression svr: 主页 -&gt; Regression -&gt; 1.4.2. Regression 对拟合概念不太理解的同学可参考： 维基百科 Andrew Ng课程第三章 Day4&amp;5:阅读论文，学习语义相似度计算的方法前面几天已经学习了一些基本的工具和方法，接下来需要开始思考如何使用自己所学习到的内容（可以不在这几天的课程之类）来完成相似度预测的任务。以下几篇论文作为参考方法，可以采用提到的任意一种方法作为最终的实现方案，有余力的同学也可以实现多个方案。 参考阅读材料： http://nlp.arizona.edu/SemEval-2017/pdf/SemEval025.pdf http://www.aclweb.org/anthology/S/S14/S14-2039.pdf http://nlp.arizona.edu/SemEval-2017/pdf/SemEval001.pdf Day6: 参考方案，进行相似度预测 如果大家已经完成自己系统的搭建并提交预测数据，那么恭喜。如果没有，可以参考本链接 中的做法，计算两个句子的相似度后再和人工的语义打分进行拟合。最后提交结果。 个人总结主办方自诩难度比价高，任务量比较大，但这一论断应该是就新手而言。有过相关大数据与人工智能开发经验的人很多概念都应该已经掌握了，甚至能直接上手建模型了。事实情况也确实如此，任务发布三天半之后，超过一半的学员已经有过结果提交记录了，打榜也比较激烈，证明前期的学习难度确实不大。]]></content>
  </entry>
  <entry>
    <title><![CDATA[【论文笔记】词向量的生成与语言模型(开发中...)]]></title>
    <url>%2F2018%2F01%2F20%2F%E3%80%90%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%E3%80%91%E8%AF%8D%E5%90%91%E9%87%8F%E7%9A%84%E7%94%9F%E6%88%90%E4%B8%8E%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%2F</url>
    <content type="text"><![CDATA[这篇博客介绍了六种生成词向量的模型，分别是神经语言模型（NNLM）、对数双线性语言模型(LBLM)、C&amp;W模型、CBOW模型、skip-gram模型、（Order模型）、GloVe模型。 神经语言模型（NNLM） Yoshua Bengio及其同事首先提出了一种同时学习词向量和语言模型的神经网络语言模型（NNLM）。 对于语料库中的每个样本，给出前面的词，我们使最后一个词的概率的对数似然最大化。 例如，对于语料库中的序列$w_1,w_2,…,w_n$，我们需要最大化$P(w_n|w_1,w2,…,w{n-1})$的对数似然性，其中我们把要预测的单词 $(w_n)$作为目标词。这个模型使用前面的词向量的串联作为输入： $$\begin{align} \begin{split} x=[e(w_1),...,e(w_{n-2}),e(w_{n-1})] \end{split} \end{align}$$ 模型结构是一个带有一个隐藏层的前馈神经网络： $$\begin{align} \begin{split} h &amp;= tanh(d + Hx) \\ y &amp;= b + Uh \end{split} \end{align}$$ 其中$U$是变换矩阵，$b$和$d$是偏差向量。最后一步是应用softmax层来获得目标词的概率。]]></content>
  </entry>
  <entry>
    <title><![CDATA[【论文笔记】评价词向量性能的八个任务]]></title>
    <url>%2F2018%2F01%2F18%2F%E3%80%90%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%E3%80%91%E8%AF%84%E4%BB%B7%E8%AF%8D%E5%90%91%E9%87%8F%E6%80%A7%E8%83%BD%E7%9A%84%E5%85%AB%E4%B8%AA%E4%BB%BB%E5%8A%A1%2F</url>
    <content type="text"><![CDATA[词向量的优劣可以从三个任务类型的八个任务进行综合评定。此篇博文简述了评价词向量性能的八个任务。 语义属性（Sementic Properties)词语相似度（Word Similarity）测试过程用的是WordSimilarity-353测试集，他包含353对英文词汇和人工对这些词对之间的语义相关度的评测值。词向量的效果比较的是两个词向量的余弦距离的Pearson相关性与人工打分的平均分数的相似程度。 同义词选择题(Synonym Question)测试过程用的是托福考试中的80个同义词选择题，每道选择题有四个选项，选择问题与选项中余弦距离最近的选项，并评估最终整体的准确性。 语义类比问题（Semantic Analogy Question）完成大约9000个语义类比问题，问题类似于“ man is to (woman) as king is to queen”。通过计算（queen-king+man）的最近词向量作为问题的答案，并评估整体的准确性。 语法类比问题（Syntactic Amalogy Question）完成大约10500个语法类比问题，问题类似于“ predict is to (predicting) as dance is to dancing”, 通过计算（dancing - dance + predict）的最近词向量作为问题的答案，并评估整体的准确性。 将词向量作为特征 (Embedding as Features)文本分类 (Text Classification)使用词向量的加权平均值作为文本的表示，然后应用逻辑回归来执行文本分类。 每个单词的权重是其出现频率。使用的数据集是IMDB数据集。 命名实体识别 (Named entity recognization)用词向量初始化神经网络 (Embedding as the Initialization of Neural Networks) 在最近的NLP任务的神经网络方法中，词向量被用来初始化第一层。 句子情感分析 (sentence-level sentiment classfication)使用卷积神经网络(CNN)在斯坦福情绪树库数据集上进行句子情感分类，重复实验五次，并展示这些实验的平均准确性。 词性标注 (Part-of-speech Tagging)们使用Ronan Collobert及其同事提出的神经网络对华尔街日报数据进行词性标注，并评估准确性。]]></content>
  </entry>
  <entry>
    <title><![CDATA[【基础定义】异构数据融合与共享项目基础定义总结]]></title>
    <url>%2F2017%2F11%2F18%2F%E3%80%90%E5%9F%BA%E7%A1%80%E5%AE%9A%E4%B9%89%E3%80%91%E5%BC%82%E6%9E%84%E6%95%B0%E6%8D%AE%E8%9E%8D%E5%90%88%E4%B8%8E%E5%85%B1%E4%BA%AB%E5%9F%BA%E7%A1%80%E5%AE%9A%E4%B9%89%E6%80%BB%E7%BB%93%2F</url>
    <content type="text"><![CDATA[AOP思想AOP为Aspect Oriented Programming的缩写，意为：面向切面编程，通过预编译方式和运行期动态代理实现程序功能的统一维护的一种技术。AOP是OOP的延续，是软件开发中的一个热点，也是Spring框架中的一个重要内容，是函数式编程的一种衍生范型。利用AOP可以对业务逻辑的各个部分进行隔离，从而使得业务逻辑各部分之间的耦合度降低，提高程序的可重用性，同时提高了开发的效率。 这样看来，AOP其实只是OOP的补充而已。OOP从横向上区分出一个个的类来，而AOP则从纵向上向对象中加入特定的代码。有了AOP，OOP变得立体了。如果加上时间维度，AOP使OOP由原来的二维变为三维了，由平面变成立体了。从技术上来说，AOP基本上是通过代理机制实现的。 refs： AOP （面向切面编程） 什么是面向切面编程AOP？ CAP原理 Consistency(一致性), 数据一致更新，所有数据变动都是同步的 Availability(可用性), 好的响应性能 Partition tolerance(分区容错性) 可靠性 定理：任何分布式系统只可同时满足二点，没法三者兼顾。 忠告：架构师不要将精力浪费在如何设计能满足三者的完美分布式系统，而是应该进行取舍。 refs: CAP原理和BASE思想 ACID模型关系数据库的ACID模型拥有 高一致性 + 可用性 很难进行分区： Atomicity 原子性：整个事务中的所有操作，要么全部完成，要么全部不完成，不可能停滞在中间某个环节。 Consistency 一致性. 一个事务可以封装状态改变（除非它是一个只读的）。事务必须始终保持系统处于一致的状态，不管在任何给定的时间并发事务有多少。 Isolation 隔离性. 如果有两个事务，运行在相同的时间内，执行相同的功能，事务的隔离性将确保每一事务在系统中认为只有该事务在使用系统。事务将假定只有它自己在操作数据库，彼此不知晓。 Durability 持久性. 在事务完成以后，该事务对数据库所作的更改便持久的保存在数据库之中，并不会被回滚。 refs: CAP原理和BASE思想 acid （数据库事务正确执行的四个基本要素的缩写） BASE思想BASE模型反ACID模型，完全不同ACID模型，牺牲高一致性，获得可用性或可靠性： Basically Available 基本可用。基本可用是指分布式系统在出现故障的时候，允许损失部分可用性，即保证核心可用。 Soft state 软状态 状态可以有一段时间不同步，异步。软状态是指允许系统存在中间状态，而该中间状态不会影响系统整体可用性。分布式存储中一般一份数据至少会有三个副本，允许不同节点间副本同步的延时就是软状态的体现。 Eventually consistent 最终一致，最终数据是一致的就可以了，而不是时时高一致。最终一致性是指系统中的所有数据副本经过一定时间后，最终能够达到一致的状态。弱一致性和强一致性相反，最终一致性是弱一致性的一种特殊情况。 ACID是传统数据库常用的设计理念，追求强一致性模型。BASE支持的是大型分布式系统，提出通过牺牲强一致性获得高可用性。 ACID和BASE代表了两种截然相反的设计哲学，在分布式系统设计的场景中，系统组件对一致性要求是不同的，因此ACID和BASE又会结合使用。 refs: CAP原理和BASE思想 分布式系统的BASE理论 ASRASR：重要的架构需求，会对架构产生深远影响的需求； ASR的几种获取方法：需求文档，采访利益相关者，理解商业目标，效应数； SOA模型面向服务的架构（SOA）是一个组件模型，它将应用程序的不同功能单元（称为服务）通过这些服务之间定义良好的接口和契约联系起来。 SOA的精髓是严格的松散耦合，大家按照一个契约（service interface）来进行交流，不允许shared memory，不允许back door，不允许直接访问其它服务的数据。]]></content>
  </entry>
  <entry>
    <title><![CDATA[【机器学习】（开发中...）]]></title>
    <url>%2F2017%2F11%2F18%2F%E3%80%90%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E3%80%91%E7%BA%BF%E6%80%A7%E5%88%86%E7%B1%BB%E3%80%81%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%E5%92%8C%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%2F</url>
    <content type="text"><![CDATA[正在开发中…$F_{\mu}$$F_a + F_b = F_c$ $F_a = F_b + F_c + F_{\mu}$ 公式是这样的 $F_a = F_b + F_c + F_{\mu}$，你必须理解它，才能看懂下面这些公式： $$\begin{aligned} \dot{x} &amp; = \sigma(y-x) \\ \dot{y} &amp; = \rho x - y - xz \\ \dot{z} &amp; = -\beta z + xy \end{aligned}$$ 实验目的 进一步理解线性回归和梯度下降的原理。 在小规模数据集上实践。 体会优化和调参的过程。 数据集 线性回归使用的是LIBSVM Data中的Housing数据，包含506个样本，每个样本有13个属性。请自行下载scaled版本，并将其切分为训练集，验证集。 线性分类使用的是LIBSVM Data中的australian数据，包含690个样本，每个样本有14 个属性。请自行下载scaled版本，并将其切分为训练集，验证集。 实验步骤线性回归和梯度下降 读取实验数据，使用sklearn库的load_svmlight_file函数读取数据。 将数据集切分为训练集和验证集，本次实验不切分测试集。使用train_test_split函数切分数据集。 线性模型参数初始化，可以考虑全零初始化，随机初始化或者正态分布初始化。选择Loss函数及对其求导，过程详见课件ppt。求得所有样本对Loss函数的梯度。取梯度的负方向，记为。更新模型参数，。为学习率，是人为调整的超参数。在训练集上测试并得到Loss函数值，在验证集上测试并得到Loss函数值。重复步骤5-8若干次，画出和随迭代次数的变化图。$F$ $$\begin{eqnarray}\nabla\cdot\vec{E} &amp;=&amp; \frac{\rho}{\epsilon_0} \\nabla\cdot\vec{B} &amp;=&amp; 0 \\nabla\times\vec{E} &amp;=&amp; -\frac{\partial B}{\partial t} \\nabla\times\vec{B} &amp;=&amp; \mu_0\left(\vec{J}+\epsilon_0\frac{\partial E}{\partial t} \right)\end{eqnarray}$$]]></content>
  </entry>
  <entry>
    <title><![CDATA[【项目笔记】iGEM wiki项目总结]]></title>
    <url>%2F2017%2F11%2F08%2FiGEM-wiki%2F</url>
    <content type="text"><![CDATA[项目描述该项目是为SCUT—China_A队伍制作wiki主页。项目比较简单，就是用基本的HTML+CSS+JavaScript写一个网站，大约有20个页面。页面设计是扁平化的极简风格的三栏式布局。项目因为一直没有收到设计稿，项目无法进行，最终在wiki freeze前四天正式开始编码，用时近两天半完成了整个网站的制作。开发过程中基本采用敏捷式开发方法，跟设计组采用流水线的工作形式，迭代开发每一个网页。 项目成果http://2017.igem.org/Team:SCUT-China_A 项目收获 重新熟悉了基础的前端语法 所在的队伍极有可能拿到一个国际级奖项 认识了一群非常可爱而优秀的小伙伴 项目难点 iGEM官方提供了服务器，这减少了搭建网站的工作量，但官方提供的代码编辑器非常难用，而且默认模板样式很诡异，而且会覆盖所提及网页的样式，需要自己再重新把平台覆盖的样式覆盖掉。 wiki tools平台会先解析一遍上传的代码，并做出一些匪夷所思的更改，比如说把 &amp;&amp; 替换成 &amp;amp ;&amp;amp ;。这个问题怀疑是平台传输代码数据时造成的更改，但一时间难以找到真正原因，所以采取的解决办法就是用嵌套选择语句代替&amp;&amp;语句。 设计组的设计稿交付不及时，这导致严重的项目赶工情况的发生。编码的那两天半里每天熬夜到三四点，以后一定要催促设计组及时交付文档。 项目难度不大，但是工作量大，基本是重复性的搬砖工作。所以将图片上传等简单的工作交给其他人来完成，并且教会了一至两个人写简单的HTML代码，这大大减少了我的工作量。]]></content>
  </entry>
  <entry>
    <title><![CDATA[【解决方案】robo3t 1.1在ubuntu 16.04中无法打开的解决方案]]></title>
    <url>%2F2017%2F08%2F10%2F16-04%E4%B8%AD%E6%97%A0%E6%B3%95%E6%89%93%E5%BC%80%E7%9A%84%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88%2F</url>
    <content type="text"><![CDATA[问题描述robo3t 1.1在ubuntu 16.04中无法打开，具体表现为双击robo3t可执行文件无反应，用终端 ./robo3t 命令报错为 1234567This application failed to start because it could not find or load the Qt platform plugin &quot;xcb&quot;in &quot;&quot;.Available platform plugins are: xcb.Reinstalling the application may fix this problem.已放弃 (核心已转储) 解决方案删除lib中的libstdc++* 按顺序执行这三句命令： 123mkdir ~/robo-backupmv robo3t-1.1.1-linux-x86_64-c93c6b0/lib/libstdc++* ~/robo-backup/robo3t-1.1.1-linux-x86_64-c93c6b0/bin/robo3t 即可完美解决该问题 ref：https://github.com/Studio3T/robomongo/issues/1385]]></content>
  </entry>
  <entry>
    <title><![CDATA[【解决方案】Chrome更新至58.0后XX.net无法使用，提示“请检查浏览器代理设置”的解决方案]]></title>
    <url>%2F2017%2F05%2F26%2FChrome%E6%9B%B4%E6%96%B0%E8%87%B358-0%E5%90%8EXX-net%E6%97%A0%E6%B3%95%E4%BD%BF%E7%94%A8%EF%BC%8C%E6%8F%90%E7%A4%BA%E2%80%9C%E8%AF%B7%E6%A3%80%E6%9F%A5%E6%B5%8F%E8%A7%88%E5%99%A8%E4%BB%A3%E7%90%86%E8%AE%BE%E7%BD%AE%E2%80%9D%E7%9A%84%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88%2F</url>
    <content type="text"><![CDATA[chrome 更新至58.0后，部分用户会发现xx-net无法使用，并提示“请检查浏览器代理设置”，且日志中反复出现 con failed（连接失败），解决方法如下： 1.将xx-net更新至测试版3.3.2或者稳定版3.3.1下载地址： https://github.com/XX-net/XX-Net/blob/master/code/default/download.md2.删除安装文件夹/data/gae_proxy文件夹下的certs文件夹和CA.crt文件3.在Chrome游览器的设置中删除已导入的xx-net的证书，删除方法参考官方文档https://github.com/XX-net/XX-Net/wiki/%E8%AF%81%E4%B9%A6%E9%94%99%E8%AF%AF（删除后，如有必要请重新手动添加证书，不过大多数情况下该步骤都能自动完成）4.检查SwitchyOmega的代理设置（如果没有更改过可跳过该步骤）5.启动xx-net，如无意外，xx-net可正常运行（升级xx-net可能需要重新部署服务端并配置，可参考官方文档https://github.com/XX-net/XX-Net/wiki/how-to-create-my-appids ） 如有疑问，请留言讨论]]></content>
  </entry>
  <entry>
    <title><![CDATA[【LeetCode刷题记录】9. Palindrome Number]]></title>
    <url>%2F2017%2F04%2F26%2FNumber%2F</url>
    <content type="text"><![CDATA[Description:Determine whether an integer is a palindrome. Do this without extra space. 这道题目实现并不难，但题目要求空间复杂度为O(1), 有一定的技巧性。 Solutions:Solution 1:123456789public boolean isPalindrome(int x) &#123; int palindromeX = 0; int inputX = x; while(x&gt;0)&#123; palindromeX = palindromeX*10 + (x % 10); x = x/10; &#125; return palindromeX==inputX; &#125; 受到LeetCode 7.Reverse Integer 的启发，将原int型的数据完全反转后，比较反转后的数据与原数据是否相同，相同则为回文，反之不是。 Question：这个算法没有考虑到int型数据反转后可能存在的溢出情况，是不是有错误？Answer: 若反转后的数据比原数据大，那么它一定与原数据不相同，肯定不是回文了，所以这个算法隐性地排除了溢出的情况。 但进一步思考，判断是否为回文需要将整个数字完全反转吗？反转到一半不久可以进行比较了吗？这就引出了Solution 2。 Solution 2:12345678910bool isPalindrome(int x) &#123; if(x&lt;0|| (x!=0 &amp;&amp;x%10==0)) return false; int sum=0; while(x&gt;sum) &#123; sum = sum*10+x%10; x = x/10; &#125; return (x==sum)||(x==sum/10); &#125; 这个算法要额外考虑能被10整除的数，需要特别注意。 Solution 3:123456789101112131415161718192021222324bool isPalindrome(int x) &#123; //negative number if(x &lt; 0) return false; int len = 1; while(x / len &gt;= 10) len *= 10; while(x &gt; 0) &#123; //get the head and tail number int left = x / len; int right = x % 10; if(left != right) return false; else&#123; //remove the head and tail number x = (x % len) / 10; len /= 100; &#125; &#125; return true; &#125; 解题思路： 每次提取头尾两个数，判断它们是否相等，判断后去掉头尾两个数。]]></content>
  </entry>
  <entry>
    <title><![CDATA[【LeetCode刷题记录】7.Reverse Integer]]></title>
    <url>%2F2017%2F04%2F25%2FInteger%2F</url>
    <content type="text"><![CDATA[Description:Reverse digits of an integer. Example1: x = 123, return 321Example2: x = -123, return -321 Have you thought about this?Here are some good questions to ask before coding. Bonus points for you if you have already thought through this! If the integer’s last digit is 0, what should the output be? ie, cases such as 10, 100. Did you notice that the reversed integer might overflow? Assume the input is a 32-bit integer, then the reverse of 1000000003 overflows. How should you handle such cases? For the purpose of this problem, assume that your function returns 0 when the reversed integer overflows. Note:The input is assumed to be a 32-bit signed integer. Your function should return 0 when the reversed integer overflows. 解体思路：这道题目比较简单，难点在于溢出的判断与处理。 Solutions：Solutions 1：123456789101112131415161718int reverse(int x) &#123; const int max = 0x7fffffff; //int最大值 const int min = 0x80000000; //int最小值 long long sum = 0; while(x != 0) &#123; int temp = x % 10; sum = sum * 10 + temp; if (sum &gt; max || sum &lt; min) //溢出处理 &#123; sum = sum &gt; 0 ? max : min; return sum; &#125; x = x / 10; &#125; return sum; &#125; 将int数据类型能表示的最大值与最小值用十六进制表示出来，虽然有效，但是代码里0x7fffffff这种 hard code 不够优雅，而且容易出错。 Improved Solution 1:12345678910public int reverse(int x) &#123; long rev= 0; while( x != 0)&#123; rev= rev*10 + x % 10; x= x/10; if( rev &gt; Integer.MAX_VALUE || rev &lt; Integer.MIN_VALUE) return 0; &#125; return (int) rev; &#125; int数据类型能表现的上下限以 Integer.MAX_VALUE 和 Integer.MIN_VALUE 表示，更加优雅简洁。 Solution 2:12345678910111213141516public int reverse(int x)&#123; int result = 0; while (x != 0) &#123; int tail = x % 10; int newResult = result * 10 + tail; if ((newResult - tail) / 10 != result) &#123; return 0; &#125; result = newResult; x = x / 10; &#125; return result;&#125; 原理： If overflow exists, the new result will not equal to the previous one.]]></content>
  </entry>
  <entry>
    <title><![CDATA[【LeetCode刷题记录】1.Two Sum解法与Hashmap的应用]]></title>
    <url>%2F2017%2F04%2F24%2FSum%E8%A7%A3%E6%B3%95%E4%B8%8EHashmap%E7%9A%84%E5%BA%94%E7%94%A8%2F</url>
    <content type="text"><![CDATA[Description:Given an array of integers, return indices of the two numbers such that they add up to a specific target. You may assume that each input would have exactly one solution, and you may not use the same element twice. Example:Given nums = [2, 7, 11, 15], target = 9,Because nums[0] + nums[1] = 2 + 7 = 9,return [0, 1]. My solution:12345678910 public int[] twoSum(int[] nums, int target) &#123; for(int i = 0; i &lt; nums.length; i++)&#123; for(int j = 0; j &lt; nums.length; j++)&#123; if(nums[i] + nums[j] == target &amp;&amp; i!=j)&#123; return new int [] &#123;i, j&#125;; &#125; &#125; &#125; return null;&#125; Runtime：56msYour runtime beats 9.43% of java submissions. 显然时间复杂度为O(n^2)，耗时太长，不太合理。 Better Solutions:以下为其他人提交的时间复杂度为O(n)的算法。 C++123456789101112131415161718192021vector&lt;int&gt; twoSum(vector&lt;int&gt; &amp;numbers, int target)&#123; //Key is the number and value is its index in the vector. unordered_map&lt;int, int&gt; hash; vector&lt;int&gt; result; for (int i = 0; i &lt; numbers.size(); i++) &#123; int numberToFind = target - numbers[i]; //if numberToFind is found in map, return them if (hash.find(numberToFind) != hash.end()) &#123; //+1 because indices are NOT zero based result.push_back(hash[numberToFind] + 1); result.push_back(i + 1); return result; &#125; //number was not found. Put it in the map. hash[numbers[i]] = i; &#125; return result;&#125; Java12345678910111213public int[] twoSum(int[] numbers, int target) &#123; int[] result = new int[2]; Map&lt;Integer, Integer&gt; map = new HashMap&lt;Integer, Integer&gt;(); for (int i = 0; i &lt; numbers.length; i++) &#123; if (map.containsKey(target - numbers[i])) &#123; result[1] = i + 1; result[0] = map.get(target - numbers[i]); return result; &#125; map.put(numbers[i], i + 1); &#125; return result;&#125; Maybe The Shorest Solution123456789public int[] twoSum(int[] nums, int target) &#123; HashMap&lt;Integer, Integer&gt; map = new HashMap&lt;&gt;(); for(int i = 0; i &lt; nums.length; i++)&#123; if(map.containsKey(target - nums[i])) return new int[] &#123;map.get(target - nums[i]) + 1, i + 1&#125;; else map.put(nums[i], i); &#125; return null; &#125; 为什么要用Hashmap？Hashmap根据键的hashCode值存储数据，大多数情况下可以直接定位到它的值，因而具有很快的访问速度，为了将时间复杂度降到O(n)，我们使用了Hashmap。 methods of Hashmap HashMap() 构造一个具有默认初始容量 (16) 和默认加载因子 (0.75) 的空 HashMap。 HashMap(int initialCapacity) 构造一个带指定初始容量和默认加载因子 (0.75) 的空 HashMap HashMap(int initialCapacity, float loadFactor) 构造一个带指定初始容量和加载因子的空 HashMap void clear() 从此映射中移除所有映射关系。 boolean containsKey(Object key) 如果此映射包含对于指定的键的映射关系，则返回 true。 boolean containsValue(Object value) 如果此映射将一个或多个键映射到指定值，则返回 true。 V put(K key, V value) 在此映射中关联指定值与指定键。- 在HashMap中通过get()来获取value，通过put()来插入value，ContainsKey()则用来检验对象是否已经存在。可以看出，和ArrayList的操作相比，HashMap除了通过key索引其内容之外，别的方面差异并不大。 使用HashMap后，运行速度相比于原来的275ms确实有明显提升 Runtime: 8msYour runtime beats 56.48% of java submissions.]]></content>
  </entry>
</search>
